{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918c96f-ad1a-4b7e-9bee-c2c48bc7f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of values for names column.\n",
    "\n",
    "students = ['Sally', 'Jane', 'Suzie', 'Billy', 'Ada', 'John', 'Thomas',\n",
    "            'Marie', 'Albert', 'Richard', 'Isaac', 'Alan']\n",
    "\n",
    "# Randomly generate arrays of scores for each student for each subject.\n",
    "# Note that all the values need to have the same length here.\n",
    "\n",
    "math_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "english_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "reading_grades = np.random.randint(low=60, high=100, size=len(students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f17639-cf51-4ea1-8103-a2f87f2214aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name': students,\n",
    "                   'math': math_grades,\n",
    "                   'english': english_grades,\n",
    "                   'reading': reading_grades,\n",
    "                   'classroom': np.random.choice(['A', 'B'], len(students))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36b16d-5b9b-4cfb-a072-3a6812284f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be5149c5-9f84-457a-b244-b8cf32d57508",
   "metadata": {},
   "source": [
    "## Indexing and Subsetting\n",
    "\n",
    "Like the pandas Series object, the pandas DataFrame object supports both position- and label-based indexing using the indexing operator `[]`.\n",
    "\n",
    "I will demonstrate concrete examples of indexing using the indexing operator `[]` alone and with the `.loc` and `.iloc` attributes below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950721c-81e4-4b99-85b5-82938dcc5a23",
   "metadata": {},
   "source": [
    "### `[]`\n",
    "\n",
    "I can pass a list of columns from a DataFrame to the indexing operator (aka bracket notation) to return a subset of my original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e8f02-2ee3-406a-972d-26847fea261a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52d84e-a4aa-42e4-b879-882c6b97d4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686fa29-8eff-4735-8874-443b7a1352ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b771d-f7af-4e6f-8d0b-abdf9299c532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4c38d-8ca7-45f0-b1a3-7d6ac11a8a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328492ee-d9cb-4f94-ac08-df2e77f8c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2231be-dc53-4a25-8935-6850cf2adaec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5488d9d-58bd-4a20-86ab-aea2f6beaf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can choose a single column using bracket notation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bf6c6-3e14-4361-a9fc-7f8f7cfc2e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e79b1-a930-42a4-b06d-3e1a7c36da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can pass a boolean Series to the indexing operator as a selector.\n",
    "# names that start with a?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6dc48-6f1f-4ccc-8d15-7481bb3a1a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42d63c3-51f3-42a6-9bb5-3649ee50bab9",
   "metadata": {},
   "source": [
    "### `.loc`\n",
    "\n",
    "We can use the `.loc` attribute to select specific rows AND columns by index label. The index label can be a number, but it can also be a string label. This method offers a lot of flexibility! **The .loc attribute's indexing is inclusive and uses an index label, not position.**\n",
    "\n",
    "```python\n",
    "df.loc[row_indexer, column_indexer]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c788e33-97cd-4ab4-920f-76fc2bc34fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c200d-b2fd-494d-9740-ec98e559c7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9573e1-8e10-4c37-9c0a-3637823383d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a2761-b351-448a-a1f6-ccd35c7451a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the rows and a subset of columns; notice the inclusive behavior of the indexing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d46ae-e42a-4419-99c1-1a0b8cd63866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use a boolean Series as a selector with .loc, too, but I can choose rows and columns.\n",
    "# dimensionality: 0, 1: rows, columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dec17-83f8-47b5-aac0-d3865c6b34d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91bba5-c96a-46b6-835f-69c53ef518bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ed6e1e-56bd-4306-be48-ac0d3cdc8597",
   "metadata": {},
   "source": [
    "### `.iloc`\n",
    "\n",
    "We can use the `.iloc` attribute to select specific rows and colums by index position. `.iloc` does not accept a boolean Series as a selector like `.loc` does. **It takes in integers representing index position and is NOT inclusive.**\n",
    "\n",
    "```python\n",
    "df.iloc[row_indexer, column_indexer]\n",
    "```\n",
    "\n",
    "We can select rows by integer position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad78ff9-f255-408b-a544-62856eb82bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the exclusive behavior of the indexing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9e1e7-2f8a-410a-baf1-a377e3da59b4",
   "metadata": {},
   "source": [
    "We can also specify which columns we want to select:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb356cb6-b150-4908-96fd-c066880b4208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b679a3cb-0a1d-4286-b8b4-c6e1ed6557d0",
   "metadata": {},
   "source": [
    "Here we select the first 3 rows (everything up to but not including the index of 3), and the second and third columns (starting from the index of 1 up to but not including the index of 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b05bd-14d6-4b7d-baf6-9db2a14611d9",
   "metadata": {},
   "source": [
    "## Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766819b-d9ab-4779-93d3-ebc9277d22ed",
   "metadata": {},
   "source": [
    "### `.agg`\n",
    "\n",
    "The `.agg` method lets us specify a way to aggregate a series of numerical values. We pass an aggregate function or list of functions to the method that we want applied to a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf0c18-2b5f-4a8b-a44b-bd6ee2fbe01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d912056-ced4-4f60-a846-0693a10e3b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd378361-0f03-4594-bcf7-c021e6d18cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128069b5-85f8-4031-b5bd-bc348f7d5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use it on the entire df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985578ff-f3cc-45d8-b32b-c363d1f64440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91966ace-f998-435e-b42a-dcee2906d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use it on a single column in a df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b9b67-0e77-462e-a843-4788c22d9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can pass a list of functions to the .agg method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2c878-afd5-4799-a66c-581e5e323f17",
   "metadata": {},
   "source": [
    "While on the surface this seems pretty simple, `.agg` is capable of providing more detailed aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55f0bd-a2a0-4b4c-ae42-e0da1d5bd69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dba85bfe-1480-4f62-904b-864656abe931",
   "metadata": {},
   "source": [
    "### `.groupby`\n",
    "\n",
    "The `.groupby` method is used to create a grouped object, which we can then apply an aggregation on. For example, if we wanted to know the highest math grade from each classroom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db619412-796d-43b5-be79-5d4fd2603d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939bfc0d-e8a8-4649-8037-07f13bc52869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our maximum grade for our 'math' column for classroom A and B respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae2ef1-3f7a-422f-8302-dccfba9190c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8120f47-cc79-44e2-91f7-fdeed316292b",
   "metadata": {},
   "source": [
    "We can use `.agg` here to, to see multiple aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce12752-14d2-4487-ae67-83cf8da156ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure:\n",
    "# take your dataframe df\n",
    "# group by classroom column\n",
    "# use the math column --> referenced with .math (could use ['math'] instead)\n",
    "# use a math method --> aggregation via .agg\n",
    "# use these functions in agg: min, mean, max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417497be-fd94-47d0-8bf8-38267dc51248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c24550-9d92-443c-bbda-01972511a751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59dae0b-0cb8-4d37-af8e-5e1e2fc8db8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "902fce9c-61ba-456f-b9fa-c65b3239cef2",
   "metadata": {},
   "source": [
    "We can group by multiple columns as well. To demonstrate, we'll create a boolean column named `passing_math`, then group by the combination of our new feature, `passing_math`, and the classroom and calculate the average reading grade and the number of individuals in each subgroup. \n",
    "\n",
    "Let's break this problem down and code it step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772c2ea-6a32-4bfe-8ce1-062880b0bcfa",
   "metadata": {},
   "source": [
    "#### `np.where`\n",
    "\n",
    "First, we can create the new `passing_math` column using a handy NumPy function called `np.where`. It will allow us to base the new column values on whether the values in an existing column, `math`, meet a condition.\n",
    "\n",
    "```python\n",
    "np.where(condition, this_where_True, this_where_False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf6740-fb2f-4555-9e1d-aa831aebafec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c31f2-38a8-4efa-83c1-beda2eee2323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce654a-b6f3-462c-85e3-acaafa5bd0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b120666-989e-44c8-a398-8638d3643814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d49cd5-119f-411d-a794-bf80b1ae5218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5b78beb-437a-405f-9d0f-bd7feaca61ff",
   "metadata": {},
   "source": [
    "Argument descriptors:\n",
    "np.where(condition, thing if true, thing if false)\n",
    "condition: math grade is less than 70 --> df.math < 70\n",
    "output if True: 'failing'\n",
    "output if False: 'passing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a683346-86a7-47b9-b7b7-cb4c65ce5c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the new column based on an existing column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9b2f4-e38f-482d-a81a-e29f0352f823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd53d44-e6c6-4531-bcfc-1542580ab1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ba6548-a47c-4b09-8e02-dac4567d190b",
   "metadata": {},
   "source": [
    "Next, we will group by the `passing_math` and `classroom` columns and use the `.agg` method to calculate the average reading grade and the number of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd21507-fad8-499e-bf99-0594191231ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c8e22-4200-42b0-b8e3-814da7b93a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I can even clean up my columns to make my calculations clearer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e3ca5-566c-4ecf-97dc-47d8704239e5",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "\n",
    "We can interpret this output as there being 2 students failing math in classroom A with an average reading grade of 87, 6 students passing math in classroom A with an average reading grade of 87.16, and 4 students passing math in classroom B with an average reading grade of 85.25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d069ee4-9c39-4a32-b614-d41e7a828d2c",
   "metadata": {},
   "source": [
    "#### `.transform`\n",
    "\n",
    "The `.transform` method can be used to produce a series with the same length of the original dataframe where each value represents the aggregation from the subgroup resulting from the `.groupby`. \n",
    "\n",
    "For example, if we wanted to know the average math grade for each classroom and add this data back to our original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a90803-05c2-440a-8f16-89f876ebc6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "782595d7-c67e-4d13-a53c-6d67ef5487da",
   "metadata": {},
   "source": [
    "#### `.describe`\n",
    "\n",
    "Check out what I can do when I combine a `.groupby` with a `.describe`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909f2a0-4314-4230-b799-3fcc4f834767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b6e96ac-95c2-4f29-81d7-2556257adbdb",
   "metadata": {},
   "source": [
    "## Merging and Joining\n",
    "\n",
    "Pandas provides several ways to combine dataframes together. We will look at two of them below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ba8e9-e3e4-48b2-ab7d-72455c446281",
   "metadata": {},
   "source": [
    "### `pd.concat`\n",
    "\n",
    "This function takes in a list or dictionary of Series or DataFrame objects and joins them along a particular axis, row-wise axis=0 or column-wise axis=1.\n",
    "\n",
    "```python\n",
    "# For example, concat with a list of two DataFrames\n",
    "pd.concat([df1, df2], axis=0)\n",
    "```\n",
    "\n",
    "- When your list contains at least one DataFrame, a DataFrame is returned.\n",
    "\n",
    "\n",
    "- When concatenating only Series objects row-wise, axis=0, a Series is returned.\n",
    "\n",
    "\n",
    "- When concatenating Series or DataFrames column-wise, axis=1, a DataFrame is returned.\n",
    "\n",
    "```python\n",
    "# Default is set to row-wise concatenation using an outer join.\n",
    "pd.concat(objs, axis=0, join='outer')\n",
    "```\n",
    "\n",
    "When concatenating dataframes vertically, we basically are just adding more rows to an existing dataframe. In this case, the dataframes we are putting together should have the same column names[^1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872201d-2c0f-4ade-b41d-a00477786ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb3b33-dd97-4e80-9f6b-980ad09375f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde0441-8711-45a0-987d-78ea13be1ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c1cfb4-74e9-4540-9f44-7c90f99ab9e6",
   "metadata": {},
   "source": [
    "**Note** that the indices are preserved on the resulting dataframe; we could set the `ignore_index` parameter to `True` if we wanted these to be sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bbfe3-9e75-472d-a5d6-cff64229eb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "582dcf48-1ae6-4ede-be4b-b339e9d62203",
   "metadata": {},
   "source": [
    "[^1]:\n",
    "    We can concatenate dataframes with different column names, but generally this is not the behavior we want, as pandas will fill in a lot of null values into the resulting dataframe. The exception to this is if the dataframes are aligned on their index (i.e. the labels for each row), then we can provide the `axis=1` keyword argument to `pd.concat` to merge the dataframes horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9f14a-e916-434b-910c-af41b6dd7f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f294b-a09d-4843-96fc-ecc2ad90e81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29633905-a72f-440c-b93a-da79040d1fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33a06709-5534-4515-9fee-887bf8846b72",
   "metadata": {},
   "source": [
    "### `.merge`\n",
    "\n",
    "This method is similar to a SQL join. Here's a [cool read](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html#compare-with-sql-join) making a comparison between the two, if you're interested.\n",
    "\n",
    "```python\n",
    "# df.merge default settings for commonly used parameters.\n",
    "\n",
    "left_df.merge(right_df, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, indicator=False)\n",
    "```\n",
    "\n",
    "How does changing the default argument of the `how` parameter change my resulting DataFrame?\n",
    "\n",
    "`how` == Type of merge to be performed.\n",
    "\n",
    "`how=left`: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "\n",
    "`how=right`: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
    "\n",
    "`how=outer`: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
    "\n",
    "`how=inner`: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39a713-1325-4a15-b470-3d6e80f26a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the users DataFrame.\n",
    "\n",
    "users = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5, 6],\n",
    "    'name': ['bob', 'joe', 'sally', 'adam', 'jane', 'mike'],\n",
    "    'role_id': [1, 2, 3, 3, np.nan, np.nan]\n",
    "})\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff906c76-a17a-4621-84b7-395bbcc95f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roles DataFrame\n",
    "\n",
    "roles = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'name': ['admin', 'author', 'reviewer', 'commenter']\n",
    "})\n",
    "roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e3017-fe00-4d49-8862-a202fbd23e46",
   "metadata": {},
   "source": [
    "The `.merge` method will allow us to specify `left_on` and `right_on` to indicate the columns that are the keys used to merge the dataframes together. \n",
    "\n",
    "- In addition, the `how` keyword argument is used to define what type of JOIN we want to do; as we saw above, `inner` is the default setting. \n",
    "\n",
    "- For demonstration purposes, I'm also going to set the `indicator` parameter to `True`, which will create a column indicating whether the merge key appears in the `left_only`, `right_only` or `both` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396edc15-5cbe-43d3-8ff3-ca300ca05dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an outer join specifying the left and right DataFrame keys.\n",
    "\n",
    "users.merge(roles, left_on='role_id', right_on='id', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cb00c-1e62-406e-b214-954d8e5ba9aa",
   "metadata": {},
   "source": [
    "Notice that we have duplicate column names in the resulting dataframe. By default, pandas will add a suffix of `_x` to any columns in the left dataframe that are duplicated, and `_y` to any columns in the right dataframe that are duplicated. I can clean up my columns if I want to; one way would be to use method chaining, which it demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb436ef-1ce1-456a-8e39-6911127815f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_on = left table key\n",
    "# right_on = right table key\n",
    "\n",
    "# ON left.key = right.key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80476ff1-a6fb-4ace-9a84-2c09adcdb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (users.merge(roles, \n",
    "            left_on='role_id', \n",
    "            right_on='id')\n",
    "    .drop(columns='role_id')\n",
    "    .rename(columns={'id_x': 'id', \n",
    "                     'name_x': 'employee',\n",
    "                     'id_y': 'role_id',\n",
    "                     'name_y': 'role'}\n",
    "            )\n",
    ")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6adff5e-0b9a-443d-a1b4-0e931c1bf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef213f-9a4b-4bf1-83a1-e1989cccf79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='a_name_student', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73032a-bc45-4148-a715-7f9842631e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache a dataframe: turn it into a csv\n",
    "df.to_csv('students.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e1485-eab4-4486-9a63-57a86b44ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/madeleinecapper/Documents/students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345ac0b-6b06-472f-9022-2db67598613f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddb365f7-fcc3-449c-a39b-33dcf020fd9a",
   "metadata": {},
   "source": [
    "## Exercises II\n",
    "\n",
    "1. Copy the `users` and `roles` DataFrames from the examples above. \n",
    "\n",
    "2. What is the result of using a `right` join on the DataFrames? \n",
    "\n",
    "3. What is the result of using an `outer` join on the DataFrames?\n",
    "     \n",
    "4. What happens if you drop the foreign keys from the DataFrames and try to merge them?\n",
    "\n",
    "5. Load the `mpg` dataset from PyDataset. \n",
    "\n",
    "6. Output and read the documentation for the `mpg` dataset.\n",
    "\n",
    "7. How many rows and columns are in the dataset?\n",
    "\n",
    "8. Check out your column names and perform any cleanup you may want on them.\n",
    "\n",
    "9. Display the summary statistics for the dataset.\n",
    "\n",
    "10. How many different manufacturers are there?\n",
    "\n",
    "11. How many different models are there?\n",
    "\n",
    "12. Create a column named `mileage_difference` like you did in the DataFrames exercises; this column should contain the difference between highway and city mileage for each car.\n",
    "\n",
    "13. Create a column named `average_mileage` like you did in the DataFrames exercises; this is the mean of the city and highway mileage.\n",
    "\n",
    "14. Create a new column on the `mpg` dataset named `is_automatic` that holds boolean values denoting whether the car has an automatic transmission.\n",
    "\n",
    "15. Using the `mpg` dataset, find out which which manufacturer has the best miles per gallon on average?\n",
    "\n",
    "16. Do automatic or manual cars have better miles per gallon?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
